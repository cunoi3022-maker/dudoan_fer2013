import streamlit as st
import numpy as np
import cv2
from PIL import Image
from skimage.feature import hog
import joblib

# === Load m√¥ h√¨nh ƒë√£ l∆∞u ===
scaler = joblib.load("scaler.joblib")
pca = joblib.load("pca.joblib")
rf = joblib.load("rf_model.joblib")

# === H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh khu√¥n m·∫∑t ===
def preprocess_face(face_img):
    face_img = cv2.resize(face_img, (48, 48))
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    face_img = clahe.apply(face_img)
    return face_img

# === H√†m xoay ·∫£nh ===
def rotate_image(image, angle):
    h, w = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h))
    return rotated

# === H√†m ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi nhi·ªÅu g√≥c xoay ===
def detect_faces_with_rotation(gray_image, angles=[0, 90, 180, 270]):
    face_cascade = cv2.CascadeClassifier(
        cv2.data.haarcascades + "haarcascade_frontalface_default.xml"
    )

    for angle in angles:
        rotated = rotate_image(gray_image, angle) if angle != 0 else gray_image
        faces = face_cascade.detectMultiScale(rotated, scaleFactor=1.1, minNeighbors=5)
        if len(faces) > 0:
            return faces, angle, rotated

    return [], 0, gray_image  # kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t

# === Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng ===
st.title("üì∏ ·ª®ng d·ª•ng nh·∫≠n di·ªán c·∫£m x√∫c khu√¥n m·∫∑t (Fer - 2013)")
st.write("T·∫£i ·∫£nh khu√¥n m·∫∑t l√™n ƒë·ªÉ m√¥ h√¨nh d·ª± ƒëo√°n c·∫£m x√∫c (t·ª± x·ª≠ l√Ω ·∫£nh b·ªã xoay)")

uploaded_file = st.file_uploader("üì∑ Ch·ªçn ·∫£nh", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # ƒê·ªçc ·∫£nh g·ªëc
    image = Image.open(uploaded_file).convert("RGB")
    img_np_original = np.array(image)
    gray = cv2.cvtColor(img_np_original, cv2.COLOR_RGB2GRAY)

    # Th·ª≠ ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi nhi·ªÅu g√≥c xoay
    faces, used_angle, rotated_gray = detect_faces_with_rotation(gray)

    # Xoay ·∫£nh RGB t∆∞∆°ng ·ª©ng ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë√∫ng chi·ªÅu
    rotated_rgb = rotate_image(img_np_original, used_angle) if used_angle != 0 else img_np_original

    st.image(rotated_rgb, caption=f"Ph√°t hi·ªán {len(faces)} khu√¥n m·∫∑t (g√≥c xoay: {used_angle}¬∞)", use_column_width=True)

    # D·ª± ƒëo√°n c·∫£m x√∫c cho t·ª´ng khu√¥n m·∫∑t
    for (x, y, w, h) in faces:
        face = rotated_gray[y:y + h, x:x + w]
        face_processed = preprocess_face(face)

        # === HOG ƒë·∫∑c tr∆∞ng ===
        features = hog(
            face_processed,
            orientations=9,
            pixels_per_cell=(4, 4),
            cells_per_block=(2, 2),
            block_norm='L2-Hys'
        ).reshape(1, -1)

        # === Chu·∫©n h√≥a + PCA ===
        features_scaled = scaler.transform(features)
        features_pca = pca.transform(features_scaled)

        # === D·ª± ƒëo√°n c·∫£m x√∫c ===
        prediction = rf.predict(features_pca)[0]

        # === V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh ƒë√£ xoay ===
        cv2.rectangle(rotated_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(
            rotated_rgb,
            prediction.capitalize(),
            (x, y - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.9,
            (0, 255, 0),
            2
        )

    # Hi·ªÉn th·ªã ·∫£nh k·∫øt qu·∫£ cu·ªëi
    st.image(rotated_rgb, caption="--> K·∫øt qu·∫£ nh·∫≠n di·ªán c·∫£m x√∫c", use_column_width=True)
